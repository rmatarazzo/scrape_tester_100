{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Input\n",
    "Function: get_user_input\n",
    "\n",
    "Prompt the user for a search topic using a GUI dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "\n",
    "def get_user_input():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the root window\n",
    "    query = simpledialog.askstring(\"Input\", \"Enter the topic to search for:\")\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help('modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated Website Identification\n",
    "Function: search_google\n",
    "\n",
    "Perform a Google search using the provided topic.\n",
    "Fetch the search results page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_google(query):\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        raise Exception(f\"Failed to retrieve search results. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Automated Link Compilation\n",
    "Function: extract_links\n",
    "\n",
    "Parse the HTML content of the search results page.\n",
    "Extract and compile a list of the top 100 links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_links(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = []\n",
    "    for result in soup.select('.tF2Cxc')[:100]:\n",
    "        link_tag = result.select_one('a')\n",
    "        if link_tag and 'href' in link_tag.attrs:\n",
    "            links.append(link_tag['href'])\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Web Scraping Capability\n",
    "Function: test_scraping\n",
    "\n",
    "Attempt to scrape each identified link.\n",
    "Check for the presence of relevant content.\n",
    "Handle different content structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scraping(link):\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Check for relevant content (this will depend on the specific use case)\n",
    "        if soup.title:\n",
    "            return True, None  # Successfully scraped\n",
    "        else:\n",
    "            return False, \"No relevant content found\"\n",
    "    except requests.RequestException as e:\n",
    "        return False, str(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Handling\n",
    "Function: handle_errors\n",
    "\n",
    "Log errors encountered during the scraping process.\n",
    "Categorize errors with appropriate error codes.\n",
    "(This is integrated within the test_scraping function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Comprehensive Report\n",
    "Function: generate_report\n",
    "\n",
    "Compile the results into a detailed report.\n",
    "List websites that were successfully scraped and those that failed, including error details.\n",
    "Output the report in a user-friendly format (e.g., CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def generate_report(results):\n",
    "    with open('scraping_report.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['URL', 'Status', 'Error']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for result in results:\n",
    "            writer.writerow(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function to Tie Everything Together\n",
    "Function: main\n",
    "\n",
    "Orchestrates the entire workflow.\n",
    "Handles user input, search, link extraction, scraping tests, and report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    query = get_user_input()\n",
    "    if query:\n",
    "        try:\n",
    "            html = search_google(query)\n",
    "            links = extract_links(html)\n",
    "            results = []\n",
    "            for link in links:\n",
    "                success, error = test_scraping(link)\n",
    "                result = {'URL': link, 'Status': 'Success' if success else 'Failed', 'Error': error if error else 'None'}\n",
    "                results.append(result)\n",
    "            generate_report(results)\n",
    "            print(\"Report generated successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    else:\n",
    "        print(\"No query provided.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape_tester_100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
