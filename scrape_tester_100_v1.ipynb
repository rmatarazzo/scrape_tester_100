{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00B9C1C3+27395]\n\t(No symbol) [0x00B33DC4]\n\t(No symbol) [0x00A31B7F]\n\t(No symbol) [0x00A1C8E8]\n\t(No symbol) [0x00A1C809]\n\t(No symbol) [0x00A33DB0]\n\t(No symbol) [0x00AAC3F6]\n\t(No symbol) [0x00A93736]\n\t(No symbol) [0x00A67541]\n\t(No symbol) [0x00A680BD]\n\tGetHandleVerifier [0x00E53A93+2876371]\n\tGetHandleVerifier [0x00EA7F5D+3221661]\n\tGetHandleVerifier [0x00C1D634+556916]\n\tGetHandleVerifier [0x00C2474C+585868]\n\t(No symbol) [0x00B3CE04]\n\t(No symbol) [0x00B39818]\n\t(No symbol) [0x00B399B7]\n\t(No symbol) [0x00B2BF0E]\n\tBaseThreadInitThunk [0x770E7BA9+25]\n\tRtlInitializeExceptionChain [0x775FC10B+107]\n\tRtlClearBits [0x775FC08F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 194\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo query provided. Exiting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 160\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    157\u001b[0m loader \u001b[38;5;241m=\u001b[39m GoogleSearchLoader(query\u001b[38;5;241m=\u001b[39mquery)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Load and scroll through the search results, then save the HTML content\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m html_content \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_scroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m html_filename \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39msave_html(html_content)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTML content saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhtml_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mGoogleSearchLoader.load_and_scroll\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# Increased delay to allow more content to load\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m new_height \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.body.scrollHeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_height \u001b[38;5;241m==\u001b[39m last_height:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\scrape_tester_100\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:414\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    411\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    412\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\scrape_tester_100\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\scrape_tester_100\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: disconnected: not connected to DevTools\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=126.0.6478.127)\nStacktrace:\n\tGetHandleVerifier [0x00B9C1C3+27395]\n\t(No symbol) [0x00B33DC4]\n\t(No symbol) [0x00A31B7F]\n\t(No symbol) [0x00A1C8E8]\n\t(No symbol) [0x00A1C809]\n\t(No symbol) [0x00A33DB0]\n\t(No symbol) [0x00AAC3F6]\n\t(No symbol) [0x00A93736]\n\t(No symbol) [0x00A67541]\n\t(No symbol) [0x00A680BD]\n\tGetHandleVerifier [0x00E53A93+2876371]\n\tGetHandleVerifier [0x00EA7F5D+3221661]\n\tGetHandleVerifier [0x00C1D634+556916]\n\tGetHandleVerifier [0x00C2474C+585868]\n\t(No symbol) [0x00B3CE04]\n\t(No symbol) [0x00B39818]\n\t(No symbol) [0x00B399B7]\n\t(No symbol) [0x00B2BF0E]\n\tBaseThreadInitThunk [0x770E7BA9+25]\n\tRtlInitializeExceptionChain [0x775FC10B+107]\n\tRtlClearBits [0x775FC08F+191]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "\n",
    "def timestamped_filename(base_filename):\n",
    "    \"\"\"Generate a filename with a timestamp.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename, ext = os.path.splitext(base_filename)\n",
    "    return f\"{filename}_{timestamp}{ext}\"\n",
    "\n",
    "class GoogleSearchLoader:\n",
    "    def __init__(self, query):\n",
    "        self.query = query\n",
    "\n",
    "    def load_and_scroll(self):\n",
    "        \"\"\"Load search results and scroll until at least 100 items or no new items are found.\"\"\"\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        driver.get(f\"https://www.google.com/search?q={quote_plus(self.query)}\")\n",
    "\n",
    "        num_results = 0\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while num_results < 100:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(20)  # Increased delay to allow more content to load\n",
    "            \n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                try:\n",
    "                    next_button = driver.find_element(By.CSS_SELECTOR, 'a#pnnext')\n",
    "                    next_button.click()\n",
    "                    time.sleep(20)  # Wait for the next page to load\n",
    "                    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        more_results_button = driver.find_element(By.XPATH, '//a[contains(., \"More results\")]')\n",
    "                        more_results_button.click()\n",
    "                        time.sleep(20)  # Wait for more results to load\n",
    "                        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    except Exception:\n",
    "                        print(\"No more pages or unable to load more results.\")\n",
    "                        break  # No new items or next/more results button was not found\n",
    "            else:\n",
    "                last_height = new_height\n",
    "            \n",
    "            search_items = driver.find_elements(By.CSS_SELECTOR, 'div.g')\n",
    "            num_results = len(search_items)\n",
    "        \n",
    "        html_content = driver.page_source\n",
    "        driver.quit()\n",
    "        return html_content\n",
    "\n",
    "    def parse_items(self, html_content):\n",
    "        \"\"\"Parse search items from HTML content using BeautifulSoup.\"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        results = []\n",
    "        search_items = soup.select('div.g')  # Adjust the selector as needed\n",
    "        for item in search_items:\n",
    "            title_div = item.select_one('h3')\n",
    "            title = title_div.text if title_div else \"No title\"\n",
    "            link_tag = item.select_one('a')\n",
    "            link = link_tag['href'] if link_tag else None\n",
    "            snippet_div = item.select_one('div.kb0PBd')\n",
    "            snippet = snippet_div.text if snippet_div else \"No snippet available\"\n",
    "            if link:\n",
    "                results.append({\n",
    "                    \"title\": title,\n",
    "                    \"link\": link,\n",
    "                    \"snippet\": snippet\n",
    "                })\n",
    "        return results\n",
    "\n",
    "    def save_html(self, html_content, base_filename=\"google_search_results.html\"):\n",
    "        \"\"\"Save the HTML content to a timestamped file.\"\"\"\n",
    "        timestamped_file = timestamped_filename(base_filename)\n",
    "        with open(timestamped_file, 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "        return timestamped_file\n",
    "\n",
    "    def save_results_to_json(self, results, base_filename=\"parsed_search_results.json\"):\n",
    "        \"\"\"Save the parsed results to a timestamped JSON file.\"\"\"\n",
    "        json_filename = timestamped_filename(base_filename)\n",
    "        with open(json_filename, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(results, json_file, ensure_ascii=False, indent=4)\n",
    "        return json_filename\n",
    "\n",
    "def get_page_title(link):\n",
    "    try:\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        driver.get(link)\n",
    "        title = driver.title\n",
    "        driver.quit()\n",
    "        return title, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def test_link(link_info):\n",
    "    link = link_info['link']\n",
    "    title, error = get_page_title(link)\n",
    "    if error:\n",
    "        return {'link': link, 'status': 'error', 'error': error}\n",
    "    else:\n",
    "        return {'link': link, 'status': 'success', 'title': title}\n",
    "\n",
    "def test_links_concurrently(search_results):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(test_link, item): item for item in search_results}\n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def generate_report(test_results):\n",
    "    success_count = sum(1 for result in test_results if result['status'] == 'success')\n",
    "    error_count = len(test_results) - success_count\n",
    "\n",
    "    report_lines = [\n",
    "        \"Link Scrape Test Report\",\n",
    "        f\"Total Links Tested: {len(test_results)}\",\n",
    "        f\"Total Successes: {success_count}\",\n",
    "        f\"Total Errors: {error_count}\",\n",
    "        \"\",\n",
    "        \"Details:\"\n",
    "    ]\n",
    "\n",
    "    for result in test_results:\n",
    "        if result['status'] == 'success':\n",
    "            report_lines.append(f\"SUCCESS: {result['link']} - Title: {result['title']}\")\n",
    "        else:\n",
    "            report_lines.append(f\"ERROR: {result['link']} - Error: {result['error']}\")\n",
    "\n",
    "    return \"\\n\".join(report_lines)\n",
    "\n",
    "def main():\n",
    "    # Create a Tkinter root window and hide it\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    # Prompt the user for the search query using Tkinter\n",
    "    query = simpledialog.askstring(\"Input\", \"Please enter the search query topic:\")\n",
    "\n",
    "    # Check if the user provided a query\n",
    "    if query:\n",
    "        loader = GoogleSearchLoader(query=query)\n",
    "        \n",
    "        # Load and scroll through the search results, then save the HTML content\n",
    "        html_content = loader.load_and_scroll()\n",
    "        html_filename = loader.save_html(html_content)\n",
    "        print(f\"HTML content saved to {html_filename}\")\n",
    "\n",
    "        # Parse the HTML content to extract search results\n",
    "        search_results = loader.parse_items(html_content)\n",
    "        print(f\"Extracted {len(search_results)} items.\")\n",
    "\n",
    "        # Save the parsed search results to a JSON file\n",
    "        json_filename = loader.save_results_to_json(search_results)\n",
    "        print(f\"Parsed search results saved to {json_filename}\")\n",
    "\n",
    "        # Load the parsed search results from the JSON file\n",
    "        with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "            search_results = json.load(f)\n",
    "\n",
    "        # Test the links concurrently and save the results\n",
    "        test_results = test_links_concurrently(search_results)\n",
    "        output_filename = timestamped_filename('links_scrape_test.json')\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(test_results, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Test results saved to {output_filename}\")\n",
    "\n",
    "        # Generate the report\n",
    "        report = generate_report(test_results)\n",
    "        report_filename = timestamped_filename('links_scrape_report.txt')\n",
    "        with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report)\n",
    "        print(f\"Report saved to {report_filename}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No query provided. Exiting.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrape_tester_100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
